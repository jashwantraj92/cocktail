Files already downloaded and verified
Files already downloaded and verified
['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']
Training Epoch: 1 [128/50000]	Loss: 4.6414	LR: 0.000000
Training Epoch: 1 [256/50000]	Loss: 4.6233	LR: 0.000256
Training Epoch: 1 [384/50000]	Loss: 4.6428	LR: 0.000512
Training Epoch: 1 [512/50000]	Loss: 4.6586	LR: 0.000767
Training Epoch: 1 [640/50000]	Loss: 4.6011	LR: 0.001023
Training Epoch: 1 [768/50000]	Loss: 4.5952	LR: 0.001279
Training Epoch: 1 [896/50000]	Loss: 4.6557	LR: 0.001535
Training Epoch: 1 [1024/50000]	Loss: 4.6453	LR: 0.001790
Training Epoch: 1 [1152/50000]	Loss: 4.6198	LR: 0.002046
Training Epoch: 1 [1280/50000]	Loss: 4.5567	LR: 0.002302
Training Epoch: 1 [1408/50000]	Loss: 4.6122	LR: 0.002558
Training Epoch: 1 [1536/50000]	Loss: 4.5961	LR: 0.002813
Training Epoch: 1 [1664/50000]	Loss: 4.5404	LR: 0.003069
Training Epoch: 1 [1792/50000]	Loss: 4.5755	LR: 0.003325
Training Epoch: 1 [1920/50000]	Loss: 4.5956	LR: 0.003581
Training Epoch: 1 [2048/50000]	Loss: 4.5174	LR: 0.003836
Training Epoch: 1 [2176/50000]	Loss: 4.5861	LR: 0.004092
Training Epoch: 1 [2304/50000]	Loss: 4.5134	LR: 0.004348
Training Epoch: 1 [2432/50000]	Loss: 4.5872	LR: 0.004604
Training Epoch: 1 [2560/50000]	Loss: 4.5163	LR: 0.004859
Training Epoch: 1 [2688/50000]	Loss: 4.5311	LR: 0.005115
Training Epoch: 1 [2816/50000]	Loss: 4.6370	LR: 0.005371
Training Epoch: 1 [2944/50000]	Loss: 4.5884	LR: 0.005627
Training Epoch: 1 [3072/50000]	Loss: 4.4636	LR: 0.005882
Training Epoch: 1 [3200/50000]	Loss: 4.5964	LR: 0.006138
Training Epoch: 1 [3328/50000]	Loss: 4.4768	LR: 0.006394
Training Epoch: 1 [3456/50000]	Loss: 4.6652	LR: 0.006650
Training Epoch: 1 [3584/50000]	Loss: 4.5250	LR: 0.006905
Training Epoch: 1 [3712/50000]	Loss: 4.6052	LR: 0.007161
Training Epoch: 1 [3840/50000]	Loss: 4.5198	LR: 0.007417
Training Epoch: 1 [3968/50000]	Loss: 4.5076	LR: 0.007673
Training Epoch: 1 [4096/50000]	Loss: 4.6228	LR: 0.007928
Training Epoch: 1 [4224/50000]	Loss: 4.5090	LR: 0.008184
Training Epoch: 1 [4352/50000]	Loss: 4.5039	LR: 0.008440
Training Epoch: 1 [4480/50000]	Loss: 4.4786	LR: 0.008696
Training Epoch: 1 [4608/50000]	Loss: 4.4583	LR: 0.008951
Training Epoch: 1 [4736/50000]	Loss: 4.4412	LR: 0.009207
Training Epoch: 1 [4864/50000]	Loss: 4.5228	LR: 0.009463
Training Epoch: 1 [4992/50000]	Loss: 4.4472	LR: 0.009719
Training Epoch: 1 [5120/50000]	Loss: 4.5587	LR: 0.009974
Training Epoch: 1 [5248/50000]	Loss: 4.5179	LR: 0.010230
Training Epoch: 1 [5376/50000]	Loss: 4.5524	LR: 0.010486
Training Epoch: 1 [5504/50000]	Loss: 4.5517	LR: 0.010742
Training Epoch: 1 [5632/50000]	Loss: 4.5804	LR: 0.010997
Training Epoch: 1 [5760/50000]	Loss: 4.4908	LR: 0.011253
Training Epoch: 1 [5888/50000]	Loss: 4.4531	LR: 0.011509
Training Epoch: 1 [6016/50000]	Loss: 4.5724	LR: 0.011765
Training Epoch: 1 [6144/50000]	Loss: 4.4901	LR: 0.012020
Training Epoch: 1 [6272/50000]	Loss: 4.4611	LR: 0.012276
Training Epoch: 1 [6400/50000]	Loss: 4.4596	LR: 0.012532
Training Epoch: 1 [6528/50000]	Loss: 4.5322	LR: 0.012788
Training Epoch: 1 [6656/50000]	Loss: 4.5766	LR: 0.013043
Training Epoch: 1 [6784/50000]	Loss: 4.4941	LR: 0.013299
Training Epoch: 1 [6912/50000]	Loss: 4.4533	LR: 0.013555
Training Epoch: 1 [7040/50000]	Loss: 4.5132	LR: 0.013811
Training Epoch: 1 [7168/50000]	Loss: 4.5783	LR: 0.014066
Training Epoch: 1 [7296/50000]	Loss: 4.4835	LR: 0.014322
Training Epoch: 1 [7424/50000]	Loss: 4.3956	LR: 0.014578
Training Epoch: 1 [7552/50000]	Loss: 4.4326	LR: 0.014834
Training Epoch: 1 [7680/50000]	Loss: 4.6065	LR: 0.015090
Training Epoch: 1 [7808/50000]	Loss: 4.5165	LR: 0.015345
Training Epoch: 1 [7936/50000]	Loss: 4.5946	LR: 0.015601
Training Epoch: 1 [8064/50000]	Loss: 4.6189	LR: 0.015857
Training Epoch: 1 [8192/50000]	Loss: 4.5164	LR: 0.016113
Training Epoch: 1 [8320/50000]	Loss: 4.5619	LR: 0.016368
Training Epoch: 1 [8448/50000]	Loss: 4.4146	LR: 0.016624
Training Epoch: 1 [8576/50000]	Loss: 4.4583	LR: 0.016880
Training Epoch: 1 [8704/50000]	Loss: 4.4572	LR: 0.017136
Training Epoch: 1 [8832/50000]	Loss: 4.5471	LR: 0.017391
Training Epoch: 1 [8960/50000]	Loss: 4.4781	LR: 0.017647
Training Epoch: 1 [9088/50000]	Loss: 4.4282	LR: 0.017903
Training Epoch: 1 [9216/50000]	Loss: 4.3842	LR: 0.018159
Training Epoch: 1 [9344/50000]	Loss: 4.4050	LR: 0.018414
Training Epoch: 1 [9472/50000]	Loss: 4.5587	LR: 0.018670
Training Epoch: 1 [9600/50000]	Loss: 4.4299	LR: 0.018926
Training Epoch: 1 [9728/50000]	Loss: 4.4037	LR: 0.019182
Training Epoch: 1 [9856/50000]	Loss: 4.6470	LR: 0.019437
Training Epoch: 1 [9984/50000]	Loss: 4.4268	LR: 0.019693
Training Epoch: 1 [10112/50000]	Loss: 4.4193	LR: 0.019949
Training Epoch: 1 [10240/50000]	Loss: 4.3419	LR: 0.020205
Training Epoch: 1 [10368/50000]	Loss: 4.3895	LR: 0.020460
Training Epoch: 1 [10496/50000]	Loss: 4.3334	LR: 0.020716
Training Epoch: 1 [10624/50000]	Loss: 4.4486	LR: 0.020972
Training Epoch: 1 [10752/50000]	Loss: 4.4704	LR: 0.021228
Training Epoch: 1 [10880/50000]	Loss: 4.4773	LR: 0.021483
Training Epoch: 1 [11008/50000]	Loss: 4.4666	LR: 0.021739
Training Epoch: 1 [11136/50000]	Loss: 4.2305	LR: 0.021995
Training Epoch: 1 [11264/50000]	Loss: 4.3990	LR: 0.022251
Training Epoch: 1 [11392/50000]	Loss: 4.5110	LR: 0.022506
Training Epoch: 1 [11520/50000]	Loss: 4.4193	LR: 0.022762
Training Epoch: 1 [11648/50000]	Loss: 4.5136	LR: 0.023018
Training Epoch: 1 [11776/50000]	Loss: 4.2329	LR: 0.023274
Training Epoch: 1 [11904/50000]	Loss: 4.4503	LR: 0.023529
Training Epoch: 1 [12032/50000]	Loss: 4.3023	LR: 0.023785
Training Epoch: 1 [12160/50000]	Loss: 4.5148	LR: 0.024041
Training Epoch: 1 [12288/50000]	Loss: 4.3351	LR: 0.024297
Training Epoch: 1 [12416/50000]	Loss: 4.3114	LR: 0.024552
Training Epoch: 1 [12544/50000]	Loss: 4.3546	LR: 0.024808
Training Epoch: 1 [12672/50000]	Loss: 4.2833	LR: 0.025064
Training Epoch: 1 [12800/50000]	Loss: 4.2793	LR: 0.025320
Training Epoch: 1 [12928/50000]	Loss: 4.6552	LR: 0.025575
Training Epoch: 1 [13056/50000]	Loss: 4.3435	LR: 0.025831
Training Epoch: 1 [13184/50000]	Loss: 4.4394	LR: 0.026087
Training Epoch: 1 [13312/50000]	Loss: 4.3590	LR: 0.026343
Training Epoch: 1 [13440/50000]	Loss: 4.2611	LR: 0.026598
Training Epoch: 1 [13568/50000]	Loss: 4.3048	LR: 0.026854
Training Epoch: 1 [13696/50000]	Loss: 4.6060	LR: 0.027110
Training Epoch: 1 [13824/50000]	Loss: 4.2867	LR: 0.027366
Training Epoch: 1 [13952/50000]	Loss: 4.4493	LR: 0.027621
Training Epoch: 1 [14080/50000]	Loss: 4.5555	LR: 0.027877
Training Epoch: 1 [14208/50000]	Loss: 4.5313	LR: 0.028133
Training Epoch: 1 [14336/50000]	Loss: 4.5247	LR: 0.028389
Training Epoch: 1 [14464/50000]	Loss: 4.1629	LR: 0.028645
Training Epoch: 1 [14592/50000]	Loss: 4.7454	LR: 0.028900
Training Epoch: 1 [14720/50000]	Loss: 4.3408	LR: 0.029156
Training Epoch: 1 [14848/50000]	Loss: 4.6735	LR: 0.029412
Training Epoch: 1 [14976/50000]	Loss: 4.2772	LR: 0.029668
Training Epoch: 1 [15104/50000]	Loss: 4.3696	LR: 0.029923
Training Epoch: 1 [15232/50000]	Loss: 4.4905	LR: 0.030179
Training Epoch: 1 [15360/50000]	Loss: 4.4009	LR: 0.030435
Training Epoch: 1 [15488/50000]	Loss: 4.4102	LR: 0.030691
Training Epoch: 1 [15616/50000]	Loss: 4.4201	LR: 0.030946
Training Epoch: 1 [15744/50000]	Loss: 4.4846	LR: 0.031202
Training Epoch: 1 [15872/50000]	Loss: 4.3718	LR: 0.031458
Training Epoch: 1 [16000/50000]	Loss: 4.3581	LR: 0.031714
Training Epoch: 1 [16128/50000]	Loss: 4.3629	LR: 0.031969
Training Epoch: 1 [16256/50000]	Loss: 4.3076	LR: 0.032225
Training Epoch: 1 [16384/50000]	Loss: 4.2179	LR: 0.032481
Training Epoch: 1 [16512/50000]	Loss: 4.4540	LR: 0.032737
Training Epoch: 1 [16640/50000]	Loss: 4.3974	LR: 0.032992
Training Epoch: 1 [16768/50000]	Loss: 4.3465	LR: 0.033248
Training Epoch: 1 [16896/50000]	Loss: 4.2902	LR: 0.033504
Training Epoch: 1 [17024/50000]	Loss: 4.2544	LR: 0.033760
Training Epoch: 1 [17152/50000]	Loss: 4.3317	LR: 0.034015
Training Epoch: 1 [17280/50000]	Loss: 4.0871	LR: 0.034271
Training Epoch: 1 [17408/50000]	Loss: 4.1800	LR: 0.034527
Training Epoch: 1 [17536/50000]	Loss: 4.4354	LR: 0.034783
Training Epoch: 1 [17664/50000]	Loss: 4.4496	LR: 0.035038
Training Epoch: 1 [17792/50000]	Loss: 4.4084	LR: 0.035294
Training Epoch: 1 [17920/50000]	Loss: 4.2291	LR: 0.035550
Training Epoch: 1 [18048/50000]	Loss: 4.2620	LR: 0.035806
Training Epoch: 1 [18176/50000]	Loss: 4.0957	LR: 0.036061
Training Epoch: 1 [18304/50000]	Loss: 4.2778	LR: 0.036317
Training Epoch: 1 [18432/50000]	Loss: 4.2475	LR: 0.036573
Training Epoch: 1 [18560/50000]	Loss: 4.3878	LR: 0.036829
Training Epoch: 1 [18688/50000]	Loss: 4.2563	LR: 0.037084
Training Epoch: 1 [18816/50000]	Loss: 4.5476	LR: 0.037340
Training Epoch: 1 [18944/50000]	Loss: 4.3119	LR: 0.037596
Training Epoch: 1 [19072/50000]	Loss: 4.2216	LR: 0.037852
Training Epoch: 1 [19200/50000]	Loss: 4.2880	LR: 0.038107
Training Epoch: 1 [19328/50000]	Loss: 4.2093	LR: 0.038363
Training Epoch: 1 [19456/50000]	Loss: 4.2012	LR: 0.038619
Training Epoch: 1 [19584/50000]	Loss: 4.2794	LR: 0.038875
Training Epoch: 1 [19712/50000]	Loss: 4.4145	LR: 0.039130
Training Epoch: 1 [19840/50000]	Loss: 4.2296	LR: 0.039386
Training Epoch: 1 [19968/50000]	Loss: 4.1963	LR: 0.039642
Training Epoch: 1 [20096/50000]	Loss: 4.1886	LR: 0.039898
Training Epoch: 1 [20224/50000]	Loss: 4.1962	LR: 0.040153
Training Epoch: 1 [20352/50000]	Loss: 4.3730	LR: 0.040409
Training Epoch: 1 [20480/50000]	Loss: 4.3191	LR: 0.040665
Training Epoch: 1 [20608/50000]	Loss: 4.3100	LR: 0.040921
Training Epoch: 1 [20736/50000]	Loss: 4.2966	LR: 0.041176
Training Epoch: 1 [20864/50000]	Loss: 4.1746	LR: 0.041432
Training Epoch: 1 [20992/50000]	Loss: 4.1685	LR: 0.041688
Training Epoch: 1 [21120/50000]	Loss: 4.1829	LR: 0.041944
Training Epoch: 1 [21248/50000]	Loss: 4.2082	LR: 0.042199
Training Epoch: 1 [21376/50000]	Loss: 4.2773	LR: 0.042455
Training Epoch: 1 [21504/50000]	Loss: 4.1535	LR: 0.042711
Training Epoch: 1 [21632/50000]	Loss: 4.1906	LR: 0.042967
Training Epoch: 1 [21760/50000]	Loss: 4.0365	LR: 0.043223
Training Epoch: 1 [21888/50000]	Loss: 4.2357	LR: 0.043478
Training Epoch: 1 [22016/50000]	Loss: 4.2220	LR: 0.043734
Training Epoch: 1 [22144/50000]	Loss: 4.2148	LR: 0.043990
Training Epoch: 1 [22272/50000]	Loss: 4.2365	LR: 0.044246
Training Epoch: 1 [22400/50000]	Loss: 4.3068	LR: 0.044501
Training Epoch: 1 [22528/50000]	Loss: 4.3260	LR: 0.044757
Training Epoch: 1 [22656/50000]	Loss: 4.0929	LR: 0.045013
Training Epoch: 1 [22784/50000]	Loss: 4.1979	LR: 0.045269
Training Epoch: 1 [22912/50000]	Loss: 4.3856	LR: 0.045524
Training Epoch: 1 [23040/50000]	Loss: 4.2777	LR: 0.045780
Training Epoch: 1 [23168/50000]	Loss: 4.2541	LR: 0.046036
Training Epoch: 1 [23296/50000]	Loss: 4.2701	LR: 0.046292
Training Epoch: 1 [23424/50000]	Loss: 4.3191	LR: 0.046547
Training Epoch: 1 [23552/50000]	Loss: 4.2733	LR: 0.046803
Training Epoch: 1 [23680/50000]	Loss: 4.3613	LR: 0.047059
Training Epoch: 1 [23808/50000]	Loss: 4.2233	LR: 0.047315
Training Epoch: 1 [23936/50000]	Loss: 4.2722	LR: 0.047570
Training Epoch: 1 [24064/50000]	Loss: 4.2784	LR: 0.047826
Training Epoch: 1 [24192/50000]	Loss: 4.2597	LR: 0.048082
Training Epoch: 1 [24320/50000]	Loss: 4.3834	LR: 0.048338
Training Epoch: 1 [24448/50000]	Loss: 4.3803	LR: 0.048593
Training Epoch: 1 [24576/50000]	Loss: 4.2126	LR: 0.048849
Training Epoch: 1 [24704/50000]	Loss: 4.1519	LR: 0.049105
Training Epoch: 1 [24832/50000]	Loss: 4.2751	LR: 0.049361
Training Epoch: 1 [24960/50000]	Loss: 4.1005	LR: 0.049616
Training Epoch: 1 [25088/50000]	Loss: 4.2794	LR: 0.049872
Training Epoch: 1 [25216/50000]	Loss: 4.2146	LR: 0.050128
Training Epoch: 1 [25344/50000]	Loss: 4.2252	LR: 0.050384
Training Epoch: 1 [25472/50000]	Loss: 4.2417	LR: 0.050639
Training Epoch: 1 [25600/50000]	Loss: 4.3571	LR: 0.050895
Training Epoch: 1 [25728/50000]	Loss: 4.3081	LR: 0.051151
Training Epoch: 1 [25856/50000]	Loss: 4.3140	LR: 0.051407
Training Epoch: 1 [25984/50000]	Loss: 4.1613	LR: 0.051662
Training Epoch: 1 [26112/50000]	Loss: 4.2496	LR: 0.051918
Training Epoch: 1 [26240/50000]	Loss: 4.1793	LR: 0.052174
Training Epoch: 1 [26368/50000]	Loss: 4.1558	LR: 0.052430
Training Epoch: 1 [26496/50000]	Loss: 4.2473	LR: 0.052685
Training Epoch: 1 [26624/50000]	Loss: 4.2691	LR: 0.052941
Training Epoch: 1 [26752/50000]	Loss: 4.2427	LR: 0.053197
Training Epoch: 1 [26880/50000]	Loss: 4.2392	LR: 0.053453
Training Epoch: 1 [27008/50000]	Loss: 4.2828	LR: 0.053708
Training Epoch: 1 [27136/50000]	Loss: 3.9956	LR: 0.053964
Training Epoch: 1 [27264/50000]	Loss: 4.2023	LR: 0.054220
Training Epoch: 1 [27392/50000]	Loss: 4.0345	LR: 0.054476
Training Epoch: 1 [27520/50000]	Loss: 4.1700	LR: 0.054731
Training Epoch: 1 [27648/50000]	Loss: 4.1733	LR: 0.054987
Training Epoch: 1 [27776/50000]	Loss: 4.1733	LR: 0.055243
Training Epoch: 1 [27904/50000]	Loss: 4.1095	LR: 0.055499
Training Epoch: 1 [28032/50000]	Loss: 4.2469	LR: 0.055754
Training Epoch: 1 [28160/50000]	Loss: 4.1413	LR: 0.056010
Training Epoch: 1 [28288/50000]	Loss: 4.1345	LR: 0.056266
Training Epoch: 1 [28416/50000]	Loss: 4.2230	LR: 0.056522
Training Epoch: 1 [28544/50000]	Loss: 4.1800	LR: 0.056777
Training Epoch: 1 [28672/50000]	Loss: 4.0392	LR: 0.057033
Training Epoch: 1 [28800/50000]	Loss: 4.4063	LR: 0.057289
Training Epoch: 1 [28928/50000]	Loss: 4.1290	LR: 0.057545
Training Epoch: 1 [29056/50000]	Loss: 4.0820	LR: 0.057801
Training Epoch: 1 [29184/50000]	Loss: 4.1100	LR: 0.058056
Training Epoch: 1 [29312/50000]	Loss: 4.1023	LR: 0.058312
Training Epoch: 1 [29440/50000]	Loss: 4.2578	LR: 0.058568
Training Epoch: 1 [29568/50000]	Loss: 4.0521	LR: 0.058824
Training Epoch: 1 [29696/50000]	Loss: 4.2404	LR: 0.059079
Training Epoch: 1 [29824/50000]	Loss: 4.1928	LR: 0.059335
Training Epoch: 1 [29952/50000]	Loss: 3.9326	LR: 0.059591
Training Epoch: 1 [30080/50000]	Loss: 4.2108	LR: 0.059847
Training Epoch: 1 [30208/50000]	Loss: 4.2046	LR: 0.060102
Training Epoch: 1 [30336/50000]	Loss: 4.2502	LR: 0.060358
Training Epoch: 1 [30464/50000]	Loss: 3.9673	LR: 0.060614
Training Epoch: 1 [30592/50000]	Loss: 4.3064	LR: 0.060870
Training Epoch: 1 [30720/50000]	Loss: 4.1184	LR: 0.061125
Training Epoch: 1 [30848/50000]	Loss: 4.1226	LR: 0.061381
Training Epoch: 1 [30976/50000]	Loss: 4.2136	LR: 0.061637
Training Epoch: 1 [31104/50000]	Loss: 4.2351	LR: 0.061893
Training Epoch: 1 [31232/50000]	Loss: 4.1355	LR: 0.062148
Training Epoch: 1 [31360/50000]	Loss: 4.2886	LR: 0.062404
Training Epoch: 1 [31488/50000]	Loss: 4.1857	LR: 0.062660
Training Epoch: 1 [31616/50000]	Loss: 3.9990	LR: 0.062916
Training Epoch: 1 [31744/50000]	Loss: 4.0943	LR: 0.063171
Training Epoch: 1 [31872/50000]	Loss: 3.9903	LR: 0.063427
Training Epoch: 1 [32000/50000]	Loss: 4.1139	LR: 0.063683
Training Epoch: 1 [32128/50000]	Loss: 3.9934	LR: 0.063939
Training Epoch: 1 [32256/50000]	Loss: 4.3303	LR: 0.064194
Training Epoch: 1 [32384/50000]	Loss: 4.0522	LR: 0.064450
Training Epoch: 1 [32512/50000]	Loss: 4.2173	LR: 0.064706
Training Epoch: 1 [32640/50000]	Loss: 4.1034	LR: 0.064962
Training Epoch: 1 [32768/50000]	Loss: 4.1265	LR: 0.065217
Training Epoch: 1 [32896/50000]	Loss: 4.1031	LR: 0.065473
Training Epoch: 1 [33024/50000]	Loss: 4.1438	LR: 0.065729
Training Epoch: 1 [33152/50000]	Loss: 4.1200	LR: 0.065985
Training Epoch: 1 [33280/50000]	Loss: 4.1370	LR: 0.066240
Training Epoch: 1 [33408/50000]	Loss: 4.0363	LR: 0.066496
Training Epoch: 1 [33536/50000]	Loss: 4.1187	LR: 0.066752
Training Epoch: 1 [33664/50000]	Loss: 3.9974	LR: 0.067008
Training Epoch: 1 [33792/50000]	Loss: 4.0787	LR: 0.067263
Training Epoch: 1 [33920/50000]	Loss: 4.1319	LR: 0.067519
Training Epoch: 1 [34048/50000]	Loss: 4.3299	LR: 0.067775
Training Epoch: 1 [34176/50000]	Loss: 3.9296	LR: 0.068031
Training Epoch: 1 [34304/50000]	Loss: 4.2345	LR: 0.068286
Training Epoch: 1 [34432/50000]	Loss: 4.2181	LR: 0.068542
Training Epoch: 1 [34560/50000]	Loss: 4.1831	LR: 0.068798
Training Epoch: 1 [34688/50000]	Loss: 4.1947	LR: 0.069054
Training Epoch: 1 [34816/50000]	Loss: 4.1295	LR: 0.069309
Training Epoch: 1 [34944/50000]	Loss: 4.0871	LR: 0.069565
Training Epoch: 1 [35072/50000]	Loss: 3.9501	LR: 0.069821
Training Epoch: 1 [35200/50000]	Loss: 4.0347	LR: 0.070077
Training Epoch: 1 [35328/50000]	Loss: 4.1573	LR: 0.070332
Training Epoch: 1 [35456/50000]	Loss: 4.1521	LR: 0.070588
Training Epoch: 1 [35584/50000]	Loss: 3.9446	LR: 0.070844
Training Epoch: 1 [35712/50000]	Loss: 4.0265	LR: 0.071100
Training Epoch: 1 [35840/50000]	Loss: 3.9488	LR: 0.071355
Training Epoch: 1 [35968/50000]	Loss: 4.1334	LR: 0.071611
Training Epoch: 1 [36096/50000]	Loss: 4.0782	LR: 0.071867
Training Epoch: 1 [36224/50000]	Loss: 4.1372	LR: 0.072123
Training Epoch: 1 [36352/50000]	Loss: 4.1907	LR: 0.072379
Training Epoch: 1 [36480/50000]	Loss: 4.2146	LR: 0.072634
Training Epoch: 1 [36608/50000]	Loss: 4.2330	LR: 0.072890
Training Epoch: 1 [36736/50000]	Loss: 4.1255	LR: 0.073146
Training Epoch: 1 [36864/50000]	Loss: 4.0730	LR: 0.073402
Training Epoch: 1 [36992/50000]	Loss: 4.3055	LR: 0.073657
Training Epoch: 1 [37120/50000]	Loss: 4.2025	LR: 0.073913
Training Epoch: 1 [37248/50000]	Loss: 4.0500	LR: 0.074169
Training Epoch: 1 [37376/50000]	Loss: 4.1431	LR: 0.074425
Training Epoch: 1 [37504/50000]	Loss: 4.0908	LR: 0.074680
Training Epoch: 1 [37632/50000]	Loss: 4.1432	LR: 0.074936
Training Epoch: 1 [37760/50000]	Loss: 4.0527	LR: 0.075192
Training Epoch: 1 [37888/50000]	Loss: 4.0689	LR: 0.075448
Training Epoch: 1 [38016/50000]	Loss: 4.2392	LR: 0.075703
Training Epoch: 1 [38144/50000]	Loss: 3.9991	LR: 0.075959
Training Epoch: 1 [38272/50000]	Loss: 4.1163	LR: 0.076215
Training Epoch: 1 [38400/50000]	Loss: 4.0339	LR: 0.076471
Training Epoch: 1 [38528/50000]	Loss: 4.0949	LR: 0.076726
Training Epoch: 1 [38656/50000]	Loss: 4.2250	LR: 0.076982
Training Epoch: 1 [38784/50000]	Loss: 4.2401	LR: 0.077238
Training Epoch: 1 [38912/50000]	Loss: 4.0758	LR: 0.077494
Training Epoch: 1 [39040/50000]	Loss: 4.1912	LR: 0.077749
Training Epoch: 1 [39168/50000]	Loss: 4.1315	LR: 0.078005
Training Epoch: 1 [39296/50000]	Loss: 4.1921	LR: 0.078261
Training Epoch: 1 [39424/50000]	Loss: 4.1237	LR: 0.078517
Training Epoch: 1 [39552/50000]	Loss: 4.0428	LR: 0.078772
Training Epoch: 1 [39680/50000]	Loss: 4.2038	LR: 0.079028
Training Epoch: 1 [39808/50000]	Loss: 4.0144	LR: 0.079284
Training Epoch: 1 [39936/50000]	Loss: 4.1661	LR: 0.079540
Training Epoch: 1 [40064/50000]	Loss: 4.0272	LR: 0.079795
Training Epoch: 1 [40192/50000]	Loss: 3.9877	LR: 0.080051
Training Epoch: 1 [40320/50000]	Loss: 4.3084	LR: 0.080307
Training Epoch: 1 [40448/50000]	Loss: 4.0654	LR: 0.080563
Training Epoch: 1 [40576/50000]	Loss: 4.1105	LR: 0.080818
Training Epoch: 1 [40704/50000]	Loss: 4.1291	LR: 0.081074
Training Epoch: 1 [40832/50000]	Loss: 4.0895	LR: 0.081330
Training Epoch: 1 [40960/50000]	Loss: 4.0460	LR: 0.081586
Training Epoch: 1 [41088/50000]	Loss: 4.2110	LR: 0.081841
Training Epoch: 1 [41216/50000]	Loss: 3.9868	LR: 0.082097
Training Epoch: 1 [41344/50000]	Loss: 4.1180	LR: 0.082353
Training Epoch: 1 [41472/50000]	Loss: 4.1971	LR: 0.082609
Training Epoch: 1 [41600/50000]	Loss: 4.0461	LR: 0.082864
Training Epoch: 1 [41728/50000]	Loss: 4.1939	LR: 0.083120
Training Epoch: 1 [41856/50000]	Loss: 4.1261	LR: 0.083376
Training Epoch: 1 [41984/50000]	Loss: 4.1502	LR: 0.083632
Training Epoch: 1 [42112/50000]	Loss: 4.0894	LR: 0.083887
Training Epoch: 1 [42240/50000]	Loss: 4.2156	LR: 0.084143
Training Epoch: 1 [42368/50000]	Loss: 4.0367	LR: 0.084399
Training Epoch: 1 [42496/50000]	Loss: 4.1045	LR: 0.084655
Training Epoch: 1 [42624/50000]	Loss: 3.9852	LR: 0.084910
Training Epoch: 1 [42752/50000]	Loss: 4.1320	LR: 0.085166
Training Epoch: 1 [42880/50000]	Loss: 4.0953	LR: 0.085422
Training Epoch: 1 [43008/50000]	Loss: 4.2543	LR: 0.085678
Training Epoch: 1 [43136/50000]	Loss: 4.0185	LR: 0.085934
Training Epoch: 1 [43264/50000]	Loss: 4.0882	LR: 0.086189
Training Epoch: 1 [43392/50000]	Loss: 4.0175	LR: 0.086445
Training Epoch: 1 [43520/50000]	Loss: 3.9863	LR: 0.086701
Training Epoch: 1 [43648/50000]	Loss: 4.0914	LR: 0.086957
Training Epoch: 1 [43776/50000]	Loss: 4.1607	LR: 0.087212
Training Epoch: 1 [43904/50000]	Loss: 4.1623	LR: 0.087468
Training Epoch: 1 [44032/50000]	Loss: 4.0849	LR: 0.087724
Training Epoch: 1 [44160/50000]	Loss: 4.1034	LR: 0.087980
Training Epoch: 1 [44288/50000]	Loss: 4.0611	LR: 0.088235
Training Epoch: 1 [44416/50000]	Loss: 4.2032	LR: 0.088491
Training Epoch: 1 [44544/50000]	Loss: 4.0929	LR: 0.088747
Training Epoch: 1 [44672/50000]	Loss: 4.0817	LR: 0.089003
Training Epoch: 1 [44800/50000]	Loss: 4.1190	LR: 0.089258
Training Epoch: 1 [44928/50000]	Loss: 4.1908	LR: 0.089514
Training Epoch: 1 [45056/50000]	Loss: 4.1649	LR: 0.089770
Training Epoch: 1 [45184/50000]	Loss: 3.9391	LR: 0.090026
Training Epoch: 1 [45312/50000]	Loss: 3.8832	LR: 0.090281
Training Epoch: 1 [45440/50000]	Loss: 4.0379	LR: 0.090537
Training Epoch: 1 [45568/50000]	Loss: 4.1718	LR: 0.090793
Training Epoch: 1 [45696/50000]	Loss: 4.1599	LR: 0.091049
Training Epoch: 1 [45824/50000]	Loss: 4.1488	LR: 0.091304
Training Epoch: 1 [45952/50000]	Loss: 4.1187	LR: 0.091560
Training Epoch: 1 [46080/50000]	Loss: 3.9837	LR: 0.091816
Training Epoch: 1 [46208/50000]	Loss: 4.0766	LR: 0.092072
Training Epoch: 1 [46336/50000]	Loss: 4.0663	LR: 0.092327
Training Epoch: 1 [46464/50000]	Loss: 3.9572	LR: 0.092583
Training Epoch: 1 [46592/50000]	Loss: 4.1459	LR: 0.092839
Training Epoch: 1 [46720/50000]	Loss: 4.2485	LR: 0.093095
Training Epoch: 1 [46848/50000]	Loss: 4.1170	LR: 0.093350
Training Epoch: 1 [46976/50000]	Loss: 4.1583	LR: 0.093606
Training Epoch: 1 [47104/50000]	Loss: 3.9743	LR: 0.093862
Training Epoch: 1 [47232/50000]	Loss: 3.9939	LR: 0.094118
Training Epoch: 1 [47360/50000]	Loss: 3.9902	LR: 0.094373
Training Epoch: 1 [47488/50000]	Loss: 4.0567	LR: 0.094629
Training Epoch: 1 [47616/50000]	Loss: 4.0754	LR: 0.094885
Training Epoch: 1 [47744/50000]	Loss: 4.0012	LR: 0.095141
Training Epoch: 1 [47872/50000]	Loss: 3.8720	LR: 0.095396
Training Epoch: 1 [48000/50000]	Loss: 3.9647	LR: 0.095652
Training Epoch: 1 [48128/50000]	Loss: 3.9889	LR: 0.095908
Training Epoch: 1 [48256/50000]	Loss: 3.9381	LR: 0.096164
Training Epoch: 1 [48384/50000]	Loss: 3.9542	LR: 0.096419
Training Epoch: 1 [48512/50000]	Loss: 3.8784	LR: 0.096675
Training Epoch: 1 [48640/50000]	Loss: 3.9283	LR: 0.096931
Training Epoch: 1 [48768/50000]	Loss: 4.1013	LR: 0.097187
Training Epoch: 1 [48896/50000]	Loss: 3.9845	LR: 0.097442
Training Epoch: 1 [49024/50000]	Loss: 4.2170	LR: 0.097698
Training Epoch: 1 [49152/50000]	Loss: 4.0931	LR: 0.097954
Training Epoch: 1 [49280/50000]	Loss: 3.8693	LR: 0.098210
Training Epoch: 1 [49408/50000]	Loss: 3.9256	LR: 0.098465
Training Epoch: 1 [49536/50000]	Loss: 3.9845	LR: 0.098721
Training Epoch: 1 [49664/50000]	Loss: 4.3273	LR: 0.098977
Training Epoch: 1 [49792/50000]	Loss: 4.1211	LR: 0.099233
Training Epoch: 1 [49920/50000]	Loss: 4.1342	LR: 0.099488
Training Epoch: 1 [50000/50000]	Loss: 3.9256	LR: 0.099744
epoch 1 training time consumed: 527.36s
